{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuZNZWHXnJAPwgvLzUA4Yq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["我們工作的核心主張是，GPT-4達到了一種通用智能的形式，確實顯示了人工通用智能的火花。這表現\n","在它的核心心智能力（如推理、創造力和推理），它獲得專業知識的主題範圍（如文學、醫學和編碼），以\n","及它能夠完成的各種任務（如玩遊戲、使用工具、解釋自己、\n","...).要創建一個可以被稱為完整的AGI的系統，還有很多事情要做。在本文的最後，我們討論了接下來的幾個\n","步驟，包括定義AGI本身，為AGI建立LLM中的一些缺失組件，以及更好地了解最近的LLM所顯示的智能的\n","起源。"],"metadata":{"id":"QhDYdMftwedm"}},{"cell_type":"markdown","source":["10.1 Definitions of intelligence, AI, and AGI\n","\n","在本文中，我們使用了一組心理學家在1994年對智能的定義[Got97]作為指導框架來探索GPT-4的人工智能。\n","這個定義抓住了智能的一些重要方面，如推理、解決問題和抽象，但它也是模糊和不完整的。它沒有說明如\n","何衡量或比較這些能力。此外，它可能沒有反映出人工系統的具體挑戰和機會，人工系統可能有與自然系統\n","不同的目標和約束。因此，我們承認這個定義不是關於智能的最終說法，而是我們調查的一個有用的起點。\n","有大量正在進行的文獻試圖提出關於智能、人工智能和人工通用智能的更加正式和全面的定義[Goe14,\n","Cho19]，但其中沒有一個是沒有問題或爭議的。例如，Legg和Hutter[Leg08]提出了一個面向目標的人工通\n","用智能定義：智能衡量一個代理人在廣泛的環境中實現目標的能力。然而，這個定義不一定能捕捉到智能的\n","全部範圍，因為它排除了那些可以執行複雜任務或回答問題而沒有任何內在動機或目標的被動或反應系統。\n","人們可以想像，作為一種人工通用智能，例如一個聰明的神諭，它沒有機構或偏好，但可以在任何主題或領\n","域提供準確和有用的信息。此外，圍繞在廣泛的環境中實現目標的定義也意味著某種程度的普遍性或最優性\n","，這可能並不現實（當然人類智能絕不是普遍性或最優性）。 Chollet在[Cho19]中提出的定義強調了承認先\n","驗（相對於普遍性）的重要性，該定義將智能的中心放在技能獲取效率上，或者換句話說，將重點放在1994\n","年定義的一個組成部分上：從經驗中學習（這也正好是LLM的關鍵弱點之一）。 Legg和Hutter[LH07]對人工\n","通用智能的另一個候選定義是：一個能做人類能做的任何事情的系統。然而，這個定義也是有問題的，因為\n","它假設有一個單一的標准或衡量人類智能或能力的標準，而事實顯然不是這樣。人類有不同的技能、天賦、\n","偏好和限制，沒有一個人可以做任何其他人類可以做的所有事情。此外，這個定義還意味著某種人類中心主\n","義的偏見，這對人工系統來說可能並不合適或不相關。雖然我們在本文中沒有採用這些定義中的任何一個，\n","但我們認識到它們提供了關於智能的重要角度。例如，智能是否可以在沒有任何機構或內在動機的情況下實\n","現是一個重要的哲學問題。為LLMs配備代理權和內在動機是未來工作的一個迷人的重要方向"],"metadata":{"id":"NJFws7jcwel2"}},{"cell_type":"markdown","source":["10.2 On the path to more general artificial intelligence\n","\n","GPT-4（以及更普遍的LLM）應該被改進以實現更普遍的智能的一些領域包括（注意，其中許多是相互聯繫\n","的）：\n","• 信心校準：該模型很難知道什麼時候它應該有信心，什麼時候它只是在猜測。它既會編造在其訓練數\n","據中沒有出現過的事實，也會在生成的內容和提示之間表現出不一致，我們在圖1.8中稱之為開放域和\n","封閉域的幻覺。這些幻覺可以用一種自信的、有說服力的方式陳述，很難被發現。因此，這樣的世代\n","會導致錯誤，也會導致混亂和不信任。雖然在產生創造性的內容時，幻覺是一件好事，但依賴有幻覺\n","的模型所做的事實性聲明可能會付出高昂的代價，尤其是在醫療保健等高風險領域的使用。有幾種互\n","補的方法來嘗試解決幻覺問題。一種方法是改善模型的校準（通過提示或微調），使其在不可能正確\n","的情況下放棄回答，或者提供一些其他可以用於下游的信心指標。另一種適合於緩解開放領域幻覺的\n","方法是將模型所缺乏的信息插入到提示中，例如允許模型調用外部信息源，如本節中的搜索引擎。\n","5.1.對於封閉領域的幻覺，通過事後檢查使用額外的模型計算\n","也是有希望的，見圖1.8的例子。最後，在構建應用程序的用戶體驗時考慮到出現幻覺的可能性，也可\n","以成為有效緩解策略的一部分。\n","\n","• 長期記憶：該模型的上下文非常有限（目前是8000個代幣，但在計算方面不可擴展），它以一種 \"無\n","狀態 \"的方式運作，沒有明顯的方法來教該模型新的事實。事實上，我們甚至不清楚該模型是否能夠完\n","成需要不斷發展的記憶和背景的任務，例如閱讀一本書，任務是在閱讀過程中跟隨情節並理解對先前\n","章節的引用。\n","\n","• 持續的學習：該模型缺乏自我更新或適應變化的環境的能力。一旦模型被訓練好，它就是固定的，沒有任何機制可以納入新的信息或來自用戶或世界的反饋。人們可以在新的數據上對模型進行微調\n","，但這可能導致性能下降或過度擬合。鑑於訓練週期之間的潛在滯後性，當涉及到最近的訓練週期之\n","後出現的事件、信息和知識時，系統往往會過時。\n","\n","• 個性化：一些應用要求模型為特定的組織或終端用戶量身定做。該系統可能需要獲得關於一個組織的\n","運作或個人的偏好的知識。在許多情況下，系統需要在一段時間內以個性化的方式適應與人和組織的\n","動態有關的具體變化。例如，在教育環境中，人們期望系統能夠理解特定的學習風格，並隨著時間的\n","推移適應學生的進步，使其具有同情心和能力。該模型沒有任何辦法將這種個性化的信息納入其反應\n","中，只能通過使用元提示，這既有限又低效。\n","\n","• 規劃和概念性跳躍：正如第8節中的例子所表明的，該模型在執行需要提前計劃或需要 \"尤里卡想法\n","\"的任務時表現出困難，這種想法構成了完成任務過程中的不連續的概念性飛躍。換句話說，該模型在\n","需要概念跳躍的任務上表現不佳，而這種概念跳躍的形式往往是人類天才的典型代表。\n","\n","• 透明度、可解釋性和一致性：模型不僅會產生幻覺、編造事實和產生不一致的內容，而且似乎沒有\n","辦法驗證它產生的內容是否與訓練數據一致，或者是否是自洽的。雖然模型通常能夠為其決策提供高\n","質量的事後解釋（正如第6.2節所展示的那樣），但只有當導致某個決策或結論的過程被準確建模，並\n","且一個足夠強大的解釋過程也被準確建模時，使用解釋來驗證該過程才行得通（第6.2節）。這兩個條\n","件都很難驗證，而當它們失敗時，就會出現是模型的決定和它的解釋之間的不一致。由於模型對其自身的局限性沒有明確的認識，所以如果不\n","在一個狹窄的領域進行廣泛的實驗，就很難與用戶建立信任或合作。\n","\n","• 認知謬誤和非理性：該模型似乎表現出人類知識和推理的一些局限性，如認知偏差和非理性（如確認\n","的偏差、錨定和基數忽略）和統計謬誤。該模型可能會繼承其訓練數據中存在的一些偏見、成見或錯\n","誤，這可能反映了與人口的子集或更大的共同觀點和評估有關的意見或觀點的分佈。\n","\n","• 對輸入的敏感性的挑戰：該模型的反應可能對提示的框架或措辭的細節以及它們在會議中的順序非常敏\n","感。這種非穩健性表明，在工程提示及其排序方面往往需要大量的努力和實驗，而在人們沒有投入這\n","種時間和努力的情況下使用，會導致次優和不一致的推論和結果。"],"metadata":{"id":"ux-jLdy3wepG"}},{"cell_type":"markdown","source":["10.3 What is actually happening?\n","\n","我們對GPT-4的研究完全是現象學的：我們專注於GPT-4能做的令人驚訝的事情，但我們沒有解決為什麼以\n","及如何實現如此卓越的智能的基本問題。它是如何推理、計劃和創造的？當它的核心只是簡單的算法組件--\n","梯度下降和大規模變換器與極其大量的數據的結合時，它為什麼會表現出如此普遍和靈活的智能？這些問題\n","是LLM的神秘和魅力的一部分，它挑戰了我們對學習和認知的理解，激發了我們的好奇心，並推動了更深入\n","的研究。關鍵的方向包括正在進行的對LLMs中的湧現現象的研究（見[WTB+ 22]為最近的調查）。然而，儘管人們對LLM的能力問題有強烈的興趣，但迄今為止的進展相當有限\n","，只有一些玩具模型證明了一些出現的現象[BEG+ 22, ABC+ 22, JSL22]。一個普遍的假設[OCS+ 20]是，大\n","量的數據（尤其是內容的多樣性）迫使神經網絡學習通用的、有用的 \"神經迴路\"，比如在[OEN+ 22, ZBB+\n","22, LAG +22]中發現的那些，而大規模的模型為神經迴路提供足夠的冗餘和多樣性，使其專門化並微調到特\n","定任務。為大規模模型證明這些假說仍然是一個挑戰，而且，幾乎可以肯定的是，猜想只是答案的一部分。\n","在另一個思考方向上，模型的巨大規模可能有其他一些好處，比如通過連接不同的最小值使梯度下降更加有\n","效[VBB19]，或者僅僅是使高維數據的平穩擬合[ES16, BS21]。總的來說，闡明GPT-4等人工智能係統的性質\n","和機制是一項艱鉅的挑戰，突然變得重要而緊迫。"],"metadata":{"id":"TtCFoc5OwesW"}}]}