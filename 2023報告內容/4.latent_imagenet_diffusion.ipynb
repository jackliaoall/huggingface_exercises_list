{"cells":[{"cell_type":"markdown","metadata":{"id":"NUmmV5ZvrPbP"},"source":["# Class-Conditional Synthesis with Latent Diffusion Models"]},{"cell_type":"markdown","metadata":{"id":"zh7u8gOx0ivw"},"source":["Install all the requirements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FWzdTPQcNwFG"},"outputs":[],"source":["int_classes = int\n","string_classes = str"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10286,"status":"ok","timestamp":1681137209895,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"NHgUAp48qwoG","outputId":"d922ed5f-163a-44bb-d9cc-69b63128249a"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'latent-diffusion' already exists and is not an empty directory.\n","fatal: destination path 'taming-transformers' already exists and is not an empty directory.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/taming-transformers\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from taming-transformers==0.0.1) (2.0.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from taming-transformers==0.0.1) (1.22.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from taming-transformers==0.0.1) (4.65.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (3.10.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->taming-transformers==0.0.1) (3.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->taming-transformers==0.0.1) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->taming-transformers==0.0.1) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->taming-transformers==0.0.1) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->taming-transformers==0.0.1) (1.3.0)\n","Installing collected packages: taming-transformers\n","  Attempting uninstall: taming-transformers\n","    Found existing installation: taming-transformers 0.0.1\n","    Can't uninstall 'taming-transformers'. No files were found to uninstall.\n","  Running setup.py develop for taming-transformers\n","Successfully installed taming-transformers-0.0.1\n"]}],"source":["#@title Installation\n","!git clone https://github.com/CompVis/latent-diffusion.git\n","!git clone https://github.com/CompVis/taming-transformers\n","!pip install -e ./taming-transformers\n","!pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n","\n","import sys\n","sys.path.append(\".\")\n","sys.path.append('./taming-transformers')\n","from taming.models import vqgan "]},{"cell_type":"markdown","metadata":{"id":"fNqCqQDoyZmq"},"source":["Now, download the checkpoint (~1.7 GB). This will usually take 1-2 minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17730,"status":"ok","timestamp":1681137227604,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"cNHvQBhzyXCI","outputId":"5b891eea-367a-43ab-b83f-a59d159ed5fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/latent-diffusion\n","--2023-04-10 14:33:27--  https://ommer-lab.com/files/latent-diffusion/nitro/cin/model.ckpt\n","Resolving ommer-lab.com (ommer-lab.com)... 141.84.41.65\n","Connecting to ommer-lab.com (ommer-lab.com)|141.84.41.65|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1827378153 (1.7G)\n","Saving to: ‘models/ldm/cin256-v2/model.ckpt’\n","\n","models/ldm/cin256-v 100%[===================>]   1.70G  78.8MB/s    in 18s     \n","\n","2023-04-10 14:33:45 (96.7 MB/s) - ‘models/ldm/cin256-v2/model.ckpt’ saved [1827378153/1827378153]\n","\n"]}],"source":["#@title Download\n","%cd latent-diffusion/ \n","\n","!mkdir -p models/ldm/cin256-v2/\n","!wget -O models/ldm/cin256-v2/model.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/cin/model.ckpt "]},{"cell_type":"markdown","metadata":{"id":"ThxmCePqt1mt"},"source":["Let's also check what type of GPU we've got."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":840,"status":"ok","timestamp":1681137228429,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"jbL2zJ7Pt7Jl","outputId":"1b0ee4dc-e19e-43ca-9f33-0a7efe113bab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Apr 10 14:33:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"1tWAqdwk0Nrn"},"source":["Load it."]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fnGwQRhtyBhb"},"outputs":[],"source":["#@title loading utils\n","import torch\n","from omegaconf import OmegaConf\n","\n","from ldm.util import instantiate_from_config\n","\n","\n","def load_model_from_config(config, ckpt):\n","    print(f\"Loading model from {ckpt}\")\n","    pl_sd = torch.load(ckpt)#, map_location=\"cpu\")\n","    sd = pl_sd[\"state_dict\"]\n","    model = instantiate_from_config(config.model)\n","    m, u = model.load_state_dict(sd, strict=False)\n","    model.cuda()\n","    model.eval()\n","    return model\n","\n","\n","def get_model():\n","    config = OmegaConf.load(\"configs/latent-diffusion/cin256-v2.yaml\")  \n","    model = load_model_from_config(config, \"models/ldm/cin256-v2/model.ckpt\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3939,"status":"ok","timestamp":1681137232365,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"g9mpnkvxU-Ws","outputId":"908f5630-1bac-4c6b-cca5-1a4d1d21a1ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: clip in /usr/local/lib/python3.9/dist-packages (0.2.0)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.9/dist-packages (0.6.11)\n","Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from kornia) (2.0.0+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from kornia) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.10.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.9.1->kornia) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.9.1->kornia) (16.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.9.1->kornia) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.9.1->kornia) (1.3.0)\n"]}],"source":["!pip install clip kornia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6653,"status":"ok","timestamp":1681137281889,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"BPnyd-XUKbfE","outputId":"74b79c8e-89ba-491e-e0a8-24e794c22d31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading model from models/ldm/cin256-v2/model.ckpt\n","LatentDiffusion: Running in eps-prediction mode\n","DiffusionWrapper has 400.92 M params.\n","making attention of type 'vanilla' with 512 in_channels\n","Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n","making attention of type 'vanilla' with 512 in_channels\n"]}],"source":["from ldm.models.diffusion.ddim import DDIMSampler\n","#from pytorch_lightning.utilities.rank_zero import rank_zero_only\n","\n","model = get_model()\n","sampler = DDIMSampler(model)"]},{"cell_type":"markdown","metadata":{"id":"iIEAhY8AhUrh"},"source":["And go. Quality, sampling speed and diversity are best controlled via the `scale`, `ddim_steps` and `ddim_eta` variables. As a rule of thumb, higher values of `scale` produce better samples at the cost of a reduced output diversity. Furthermore, increasing `ddim_steps` generally also gives higher quality samples, but returns are diminishing for values > 250. Fast sampling (i e. low values of `ddim_steps`) while retaining good quality can be achieved by using `ddim_eta = 0.0`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":332,"output_embedded_package_id":"1mdYp7Lg5BRSMWuGFIJBLcpERsS8qXrre"},"executionInfo":{"elapsed":58264,"status":"ok","timestamp":1681137353486,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"},"user_tz":-480},"id":"jcbqWX2Ytu9t","outputId":"d2afa5db-2e91-4060-8b96-0dad41c04cc2"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np \n","from PIL import Image\n","from einops import rearrange\n","from torchvision.utils import make_grid\n","\n","\n","classes = [25, 187, 448, 992]   # define classes to be sampled here\n","n_samples_per_class = 6\n","\n","ddim_steps = 20\n","ddim_eta = 0.0\n","scale = 3.0   # for unconditional guidance\n","\n","\n","all_samples = list()\n","\n","with torch.no_grad():\n","    with model.ema_scope():\n","        uc = model.get_learned_conditioning(\n","            {model.cond_stage_key: torch.tensor(n_samples_per_class*[1000]).to(model.device)}\n","            )\n","        \n","        for class_label in classes:\n","            print(f\"rendering {n_samples_per_class} examples of class '{class_label}' in {ddim_steps} steps and using s={scale:.2f}.\")\n","            xc = torch.tensor(n_samples_per_class*[class_label])\n","            c = model.get_learned_conditioning({model.cond_stage_key: xc.to(model.device)})\n","            \n","            samples_ddim, _ = sampler.sample(S=ddim_steps,\n","                                             conditioning=c,\n","                                             batch_size=n_samples_per_class,\n","                                             shape=[3, 64, 64],\n","                                             verbose=False,\n","                                             unconditional_guidance_scale=scale,\n","                                             unconditional_conditioning=uc, \n","                                             eta=ddim_eta)\n","\n","            x_samples_ddim = model.decode_first_stage(samples_ddim)\n","            x_samples_ddim = torch.clamp((x_samples_ddim+1.0)/2.0, \n","                                         min=0.0, max=1.0)\n","            all_samples.append(x_samples_ddim)\n","\n","\n","# display as grid\n","grid = torch.stack(all_samples, 0)\n","grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n","grid = make_grid(grid, nrow=n_samples_per_class)\n","\n","# to image\n","grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n","Image.fromarray(grid.astype(np.uint8))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}